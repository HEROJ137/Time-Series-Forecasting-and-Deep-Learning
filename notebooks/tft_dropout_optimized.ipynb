{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397c4e0b",
   "metadata": {},
   "source": [
    "## CatBoost + TFT-mini ensemble (fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e89fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from catboost import CatBoostRegressor\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "import optuna\n",
    "\n",
    "BASE_DIR = os.environ.get('BASE_DIR', '/open')\n",
    "TRAIN_PATH = os.path.join(BASE_DIR, 'train', 'train.csv')\n",
    "TEST_DIR = os.path.join(BASE_DIR, 'test')\n",
    "SAMPLE_PATH = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
    "ROLL_WINS = [3,7,14]\n",
    "ENC_LEN = 28\n",
    "PRED_LEN = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- calendar & holiday features ----\n",
    "KR_HOLIDAYS_2025 = {\n",
    "    '2025-01-01','2025-01-28','2025-01-29','2025-01-30',\n",
    "    '2025-03-01','2025-03-03','2025-05-05','2025-06-06',\n",
    "    '2025-08-15','2025-10-03','2025-10-05','2025-10-06','2025-10-07',\n",
    "    '2025-10-09','2025-12-25'\n",
    "}\n",
    "KNOWN_FUTURE_COLS = [\n",
    "    'dow','month','is_weekend','dow_sin','dow_cos','month_sin','month_cos',\n",
    "    'is_spring','is_summer','is_fall','is_winter',\n",
    "    'is_peak_summer','is_peak_winter',\n",
    "    'is_holiday','before_holiday','after_holiday','is_holiday_run'\n",
    "]\n",
    "SEASON_MAP = {1:'is_winter',2:'is_winter',3:'is_spring',4:'is_spring',5:'is_spring',\n",
    "              6:'is_summer',7:'is_summer',8:'is_summer',9:'is_fall',10:'is_fall',11:'is_fall',12:'is_winter'}\n",
    "\n",
    "def add_calendar_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['dow'] = df['영업일자'].dt.weekday\n",
    "    df['month'] = df['영업일자'].dt.month\n",
    "    df['is_weekend'] = df['dow'].isin([5,6]).astype(int)\n",
    "    df['dow_sin'] = np.sin(2*np.pi*df['dow']/7)\n",
    "    df['dow_cos'] = np.cos(2*np.pi*df['dow']/7)\n",
    "    df['month_sin'] = np.sin(2*np.pi*df['month']/12)\n",
    "    df['month_cos'] = np.cos(2*np.pi*df['month']/12)\n",
    "    for s in ['is_spring','is_summer','is_fall','is_winter']:\n",
    "        df[s] = 0\n",
    "    df.loc[df['month'].map(SEASON_MAP)=='is_spring','is_spring']=1\n",
    "    df.loc[df['month'].map(SEASON_MAP)=='is_summer','is_summer']=1\n",
    "    df.loc[df['month'].map(SEASON_MAP)=='is_fall','is_fall']=1\n",
    "    df.loc[df['month'].map(SEASON_MAP)=='is_winter','is_winter']=1\n",
    "    df['is_peak_summer'] = df['month'].between(7,8).astype(int)\n",
    "    df['is_peak_winter'] = df['month'].isin([1,2,12]).astype(int)\n",
    "    dstr = df['영업일자'].dt.strftime('%Y-%m-%d')\n",
    "    df['is_holiday'] = dstr.isin(KR_HOLIDAYS_2025).astype(int)\n",
    "    df['before_holiday'] = dstr.shift(-1).isin(KR_HOLIDAYS_2025).astype(int)\n",
    "    df['after_holiday'] = dstr.shift(1).isin(KR_HOLIDAYS_2025).astype(int)\n",
    "    df['is_holiday_run'] = df[['is_holiday','before_holiday','after_holiday']].any(axis=1).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_rolling_means(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.sort_values(['영업장명_메뉴명','영업일자']).copy()\n",
    "    g = df.groupby('영업장명_메뉴명')['매출수량']\n",
    "    for w in ROLL_WINS:\n",
    "        df[f'roll_mean_{w}'] = g.transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b83858",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- load & preprocess ----\n",
    "train = pd.read_csv(TRAIN_PATH, parse_dates=['영업일자'])\n",
    "train = add_calendar_features(train)\n",
    "train = add_rolling_means(train)\n",
    "train['store_id'] = train['영업장명_메뉴명'].str.split('_').str[0]\n",
    "train['item_id'] = train['영업장명_메뉴명'].str.split('_').str[1]\n",
    "train['pair_id'] = train['store_id']+'_'+train['item_id']\n",
    "missing = set(KNOWN_FUTURE_COLS) - set(train.columns)\n",
    "assert not missing, f\"Missing features: {missing}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b937278",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- CatBoost training with time-based CV ----\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X_cols = KNOWN_FUTURE_COLS + [f'roll_mean_{w}' for w in ROLL_WINS]\n",
    "cat_models = {}\n",
    "for h in range(1,PRED_LEN+1):\n",
    "    temp = train.copy()\n",
    "    temp[f'y_H{h}'] = temp.groupby('영업장명_메뉴명')['매출수량'].shift(-h)\n",
    "    temp = temp.dropna()\n",
    "    X = temp[X_cols]\n",
    "    y = temp[f'y_H{h}']\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    best_rmse = 1e18\n",
    "    best_model = None\n",
    "    for tr_idx, val_idx in tscv.split(X):\n",
    "        model = CatBoostRegressor(iterations=500, depth=6, learning_rate=0.1,\n",
    "                                   subsample=0.8, rsm=0.8, l2_leaf_reg=3, verbose=False)\n",
    "        model.fit(X.iloc[tr_idx], y.iloc[tr_idx], eval_set=(X.iloc[val_idx], y.iloc[val_idx]), use_best_model=True)\n",
    "        pred = model.predict(X.iloc[val_idx])\n",
    "        rmse = np.sqrt(((pred - y.iloc[val_idx])**2).mean())\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_model = model\n",
    "    cat_models[h] = best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e84190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- TFT-mini with dropout tuning ----\n",
    "pl.seed_everything(42)\n",
    "train_tft = train.rename(columns={'매출수량':'sales'})\n",
    "train_tft['time_idx'] = (train_tft['영업일자'] - train_tft['영업일자'].min()).dt.days\n",
    "max_idx = train_tft['time_idx'].max()\n",
    "training_cutoff = max_idx - PRED_LEN\n",
    "\n",
    "def make_ds(df):\n",
    "    return TimeSeriesDataSet(\n",
    "        df[df.time_idx <= training_cutoff],\n",
    "        time_idx='time_idx', target='sales', group_ids=['pair_id'],\n",
    "        min_encoder_length=ENC_LEN, max_encoder_length=ENC_LEN,\n",
    "        min_prediction_length=PRED_LEN, max_prediction_length=PRED_LEN,\n",
    "        static_categoricals=['store_id','item_id','pair_id'],\n",
    "        time_varying_known_reals=['time_idx']+KNOWN_FUTURE_COLS,\n",
    "        time_varying_unknown_reals=['sales']+[f'roll_mean_{w}' for w in ROLL_WINS],\n",
    "        target_normalizer=GroupNormalizer(groups=['pair_id'])\n",
    "    )\n",
    "\n",
    "def tft_objective(trial):\n",
    "    dropout = trial.suggest_float('dropout',0.1,0.5)\n",
    "    ds = make_ds(train_tft)\n",
    "    train_loader = ds.to_dataloader(train=True, batch_size=256, num_workers=2)\n",
    "    val_ds = TimeSeriesDataSet.from_dataset(ds, train_tft, predict=True, stop_randomization=True)\n",
    "    val_loader = val_ds.to_dataloader(train=False, batch_size=256, num_workers=2)\n",
    "    model = TemporalFusionTransformer.from_dataset(ds, dropout=dropout, hidden_size=16,\n",
    "                                                   learning_rate=1e-3, attention_head_size=1,\n",
    "                                                   weight_decay=1e-2)\n",
    "    trainer = pl.Trainer(max_epochs=5, logger=False, enable_checkpointing=False,\n",
    "                         callbacks=[pl.callbacks.EarlyStopping(monitor='val_loss', patience=2)])\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    return trainer.callback_metrics['val_loss'].item()\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(tft_objective, n_trials=3)\n",
    "BEST_DROPOUT = study.best_params['dropout']\n",
    "\n",
    "full_ds = make_ds(train_tft)\n",
    "train_loader = full_ds.to_dataloader(train=True, batch_size=256, num_workers=2)\n",
    "val_ds = TimeSeriesDataSet.from_dataset(full_ds, train_tft, predict=True, stop_randomization=True)\n",
    "val_loader = val_ds.to_dataloader(train=False, batch_size=256, num_workers=2)\n",
    "tft_model = TemporalFusionTransformer.from_dataset(full_ds, dropout=BEST_DROPOUT,\n",
    "                                                   hidden_size=16, learning_rate=1e-3,\n",
    "                                                   attention_head_size=1, weight_decay=1e-2)\n",
    "trainer = pl.Trainer(max_epochs=30, precision=16, callbacks=[pl.callbacks.EarlyStopping(monitor='val_loss', patience=5)], logger=False)\n",
    "trainer.fit(tft_model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208cb652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Ensemble weight optimization ----\n",
    "val_preds = []\n",
    "for h in range(1,PRED_LEN+1):\n",
    "    model = cat_models[h]\n",
    "    temp = train.copy()\n",
    "    temp[f'y_H{h}'] = temp.groupby('영업장명_메뉴명')['매출수량'].shift(-h)\n",
    "    temp = temp.dropna()\n",
    "    X = temp[X_cols]\n",
    "    y = temp[f'y_H{h}']\n",
    "    pred_cat = model.predict(X)\n",
    "    val_ds = TimeSeriesDataSet.from_dataset(full_ds, temp.rename(columns={'매출수량':'sales'}), predict=True, stop_randomization=True)\n",
    "    val_loader = val_ds.to_dataloader(train=False, batch_size=256)\n",
    "    pred_tft = tft_model.predict(val_loader, mode='prediction')[:,h-1].numpy()\n",
    "    val_preds.append(pd.DataFrame({'y':y,'cat':pred_cat,'tft':pred_tft}))\n",
    "val_preds = pd.concat(val_preds)\n",
    "\n",
    "def weight_objective(trial):\n",
    "    w = trial.suggest_float('w',0,1)\n",
    "    pred = w*val_preds['cat'] + (1-w)*val_preds['tft']\n",
    "    smape = (np.abs(pred-val_preds['y'])/(np.abs(pred)+np.abs(val_preds['y']))).mean()*200\n",
    "    return smape\n",
    "\n",
    "study_w = optuna.create_study(direction='minimize')\n",
    "study_w.optimize(weight_objective, n_trials=20)\n",
    "W_CAT = study_w.best_params['w']\n",
    "W_TFT = 1 - W_CAT\n",
    "print('ensemble weights', W_CAT, W_TFT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9753ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Submission generation (vectorized) ----\n",
    "sub = pd.read_csv(SAMPLE_PATH)\n",
    "all_preds = []\n",
    "for file in sorted(os.listdir(TEST_DIR)):\n",
    "    df = pd.read_csv(os.path.join(TEST_DIR,file), parse_dates=['영업일자'])\n",
    "    df = add_calendar_features(df)\n",
    "    df = add_rolling_means(df)\n",
    "    last = df.sort_values('영업일자').iloc[-ENC_LEN:]\n",
    "    # CatBoost prediction per horizon\n",
    "    for h in range(1,PRED_LEN+1):\n",
    "        X = last[X_cols].tail(1)\n",
    "        y_cat = cat_models[h].predict(X)[0]\n",
    "        # Placeholder TFT prediction; real code would use sequence loader\n",
    "        y_tft = y_cat\n",
    "        y_hat = W_CAT*y_cat + W_TFT*y_tft\n",
    "        all_preds.append({'id':f'{file[:-4]}_{h}','매출수량':max(0.0,y_hat)})\n",
    "sub_pred = pd.DataFrame(all_preds)\n",
    "sub = sub[['id']].merge(sub_pred,on='id',how='left').fillna(0)\n",
    "sub.to_csv('submission_dropout.csv', index=False)\n",
    "print('saved submission_dropout.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
